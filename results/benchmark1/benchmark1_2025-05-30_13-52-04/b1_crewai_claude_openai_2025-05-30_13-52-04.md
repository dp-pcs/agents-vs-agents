## CrewAI with Claude Output

| Week | Topics | Resources | Project |
|------|--------|-----------|---------|
| 1 | Intro to Machine Learning, Types of ML (Supervised, Unsupervised, Reinforcement) | [Coursera Machine Learning](https://www.coursera.org/learn/machine-learning), [Intro to ML (Udacity)](https://www.udacity.com/course/intro-to-machine-learning--ud120) | - |  
| 2 | Linear Regression, Gradient Descent | [Linear Regression (Coursera)](https://www.coursera.org/lecture/machine-learning/model-representation-db3jS), [Gradient Descent (ML Cheatsheet)](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html) | - |
| 3 | Logistic Regression, Evaluation Metrics (Accuracy, Precision, Recall, F1) | [Logistic Regression (Towards Data Science)](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc), [Evaluation Metrics (Google Developers)](https://developers.google.com/machine-learning/crash-course/classification/accuracy) | Project 1: Build a Logistic Regression model on a binary classification dataset |
| 4 | Neural Networks, Activation Functions, Backpropagation | [Neural Networks (3Blue1Brown)](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi), [Backpropagation (Brilliant)](https://brilliant.org/wiki/backpropagation/) | - |
| 5 | Convolutional Neural Networks (CNNs) | [CNN Explainer (Towards Data Science)](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53), [CNN Course (deeplearning.ai)](https://www.coursera.org/learn/convolutional-neural-networks) | - | 
| 6 | Recurrent Neural Networks (RNNs), LSTMs | [Understanding LSTMs (Chris Olah)](https://colah.github.io/posts/2015-08-Understanding-LSTMs/), [Sequence Models Course (deeplearning.ai)](https://www.coursera.org/learn/nlp-sequence-models) | Project 2: Build a CNN for image classification or an RNN for text classification |
| 7 | Unsupervised Learning, K-Means Clustering, Dimensionality Reduction (PCA) | [Unsupervised Learning (Caltech)](http://work.caltech.edu/slides/slides13.pdf), [PCA (Towards Data Science)](https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c) | - |
| 8 | Intro to Natural Language Processing (NLP), Text Preprocessing, Bag-of-Words | [NLP Fundamentals Course (Codecademy)](https://www.codecademy.com/learn/natural-language-processing), [Text Preprocessing (Towards Data Science)](https://towardsdatascience.com/text-preprocessing-for-data-scientists-3d2419c8199d) | - |
| 9 | Word Embeddings (word2vec, GloVe), Sentiment Analysis | [Word2Vec Tutorial (Tensorflow)](https://www.tensorflow.org/tutorials/text/word2vec), [Sentiment Analysis (Towards Data Science)](https://towardsdatascience.com/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17) | Project 3: Build a sentiment analysis model using word embeddings and a neural network |
| 10 | Transformers, Attention Mechanism, BERT | [Illustrated Transformer (Jay Alammar)](https://jalammar.github.io/illustrated-transformer/), [BERT Explained (Towards Data Science)](https://towardsdatascience.com/bert-

---

## OpenAI Evaluation

| Week | Topics | Resources | Project |
|------|--------|-----------|---------|
| 1 | Intro to Machine Learning, Types of ML (Supervised, Unsupervised, Reinforcement) | [Coursera Machine Learning](https://www.coursera.org/learn/machine-learning), [Intro to ML (Udacity)](https://www.udacity.com/course/intro-to-machine-learning--ud120) | - |  
| 2 | Linear Regression, Gradient Descent | [Linear Regression (Coursera)](https://www.coursera.org/lecture/machine-learning/model-representation-db3jS), [Gradient Descent (ML Cheatsheet)](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html) | - |
| 3 | Logistic Regression, Evaluation Metrics (Accuracy, Precision, Recall, F1) | [Logistic Regression (Towards Data Science)](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc), [Evaluation Metrics (Google Developers)](https://developers.google.com/machine-learning/crash-course/classification/accuracy) | Project 1: Build a Logistic Regression model on a binary classification dataset |
| 4 | Neural Networks, Activation Functions, Backpropagation | [Neural Networks (3Blue1Brown)](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi), [Backpropagation (Brilliant)](https://brilliant.org/wiki/backpropagation/) | - |
| 5 | Convolutional Neural Networks (CNNs) | [CNN Explainer (Towards Data Science)](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53), [CNN Course (deeplearning.ai)](https://www.coursera.org/learn/convolutional-neural-networks) | - | 
| 6 | Recurrent Neural Networks (RNNs), LSTMs | [Understanding LSTMs (Chris Olah)](https://colah.github.io/posts/2015-08-Understanding-LSTMs/), [Sequence Models Course (deeplearning.ai)](https://www.coursera.org/learn/nlp-sequence-models) | Project 2: Build a CNN for image classification or an RNN for text classification |
| 7 | Unsupervised Learning, K-Means Clustering, Dimensionality Reduction (PCA) | [Unsupervised Learning (Caltech)](http://work.caltech.edu/slides/slides13.pdf), [PCA (Towards Data Science)](https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c) | - |
| 8 | Intro to Natural Language Processing (NLP), Text Preprocessing, Bag-of-Words | [NLP Fundamentals Course (Codecademy)](https://www.codecademy.com/learn/natural-language-processing), [Text Preprocessing (Towards Data Science)](https://towardsdatascience.com/text-preprocessing-for-data-scientists-3d2419c8199d) | - |
| 9 | Word Embeddings (word2vec, GloVe), Sentiment Analysis | [Word2Vec Tutorial (Tensorflow)](https://www.tensorflow.org/tutorials/text/word2vec), [Sentiment Analysis (Towards Data Science)](https://towardsdatascience.com/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17) | Project 3: Build a sentiment analysis model using word embeddings and a neural network |
| 10 | Transformers, Attention Mechanism, BERT | [Illustrated Transformer (Jay Alammar)](https://jalammar.github.io/illustrated-transformer/), [BERT Explained (Towards Data Science)](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270) | - |
| 11 | Large Language Models, GPT-3, Fine-tuning | [GPT-3 Explained (Towards Data Science)](https://towardsdatascience.com/gpt-3-the-worlds-most-powerful-language-model-6a6c1e73620b), [Fine-tuning (Hugging Face)](https://huggingface.co/transformers/training.html) | - |
| 12 | Ethics in AI, Bias in Machine Learning | [Ethics in AI (edX)](https://www.edx.org/professional-certificate/ethics-in-ai-and-big-data), [Bias in ML (Towards Data

**Time to complete:** 70.61 seconds
